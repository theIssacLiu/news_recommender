import numpy as np
import pandas as pd
from tqdm import tqdm
import pickle
import os
import random
import collections
import faiss
from sklearn.preprocessing import LabelEncoder
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader

# å®šä¹‰æ•°æ®é›†ç±»
class YouTubeDNNDataset(Dataset):
    def __init__(self, user_ids, item_seqs, target_items, labels, seq_lens, max_len=30):
        self.user_ids = torch.LongTensor(user_ids)
        self.target_items = torch.LongTensor(target_items)
        self.labels = torch.FloatTensor(labels)
        self.seq_lens = torch.LongTensor(np.minimum(seq_lens, max_len))  # ç¡®ä¿ä¸è¶…è¿‡max_len
        self.max_len = max_len
        
        # é¢„å¤„ç†æ‰€æœ‰åºåˆ—ï¼Œç¡®ä¿é•¿åº¦ä¸€è‡´
        self.padded_seqs = []
        for seq in item_seqs:
            if len(seq) > max_len:
                # æˆªæ–­è¿‡é•¿çš„åºåˆ—
                padded_seq = seq[:max_len]
            else:
                # å¡«å……è¿‡çŸ­çš„åºåˆ—
                padded_seq = seq + [0] * (max_len - len(seq))
            self.padded_seqs.append(padded_seq)
        self.padded_seqs = torch.LongTensor(self.padded_seqs)
        
    def __len__(self):
        return len(self.user_ids)
    
    def __getitem__(self, idx):
        return {
            'user_id': self.user_ids[idx],
            'hist_item_seq': self.padded_seqs[idx],
            'target_item': self.target_items[idx],
            'seq_len': self.seq_lens[idx],
            'label': self.labels[idx]
        }

# åŒå¡”æ¨¡å‹å®šä¹‰
class YouTubeDNNModel(nn.Module):
    def __init__(self, user_count, item_count, embedding_dim=16, hidden_units=(64, 16), dropout=0.2):
        super(YouTubeDNNModel, self).__init__()
        self.embedding_dim = embedding_dim
        
        # ç”¨æˆ·å’Œç‰©å“çš„åµŒå…¥å±‚
        self.user_embedding = nn.Embedding(user_count, embedding_dim)
        self.item_embedding = nn.Embedding(item_count, embedding_dim)
        
        # å†å²ç‰©å“åºåˆ—èšåˆ
        self.hist_embedding = nn.Embedding(item_count, embedding_dim)
        
        # ç”¨æˆ·å¡”æ·±åº¦ç½‘ç»œ
        layers = []
        input_dim = embedding_dim * 2  # ç”¨æˆ·IDåµŒå…¥ + å†å²åºåˆ—åµŒå…¥
        for unit in hidden_units:
            layers.append(nn.Linear(input_dim, unit))
            layers.append(nn.ReLU())
            layers.append(nn.Dropout(dropout))
            input_dim = unit
        self.user_dnn = nn.Sequential(*layers)
        
        # åˆå§‹åŒ–æƒé‡
        self._init_weights()
        
    def _init_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Embedding):
                nn.init.normal_(m.weight, mean=0.0, std=0.01)
            elif isinstance(m, nn.Linear):
                nn.init.xavier_normal_(m.weight)
                if m.bias is not None:
                    nn.init.zeros_(m.bias)
    
    def forward(self, user_id, hist_item_seq, target_item, seq_len):
        # ç”¨æˆ·ID Embedding
        user_emb = self.user_embedding(user_id)  # [B, E]
        
        # å†å²ç‰©å“åºåˆ—Embedding
        hist_emb = self.hist_embedding(hist_item_seq)  # [B, L, E]
        
        # è®¡ç®—åºåˆ—çš„å¹³å‡å€¼
        device = user_id.device
        mask = torch.arange(hist_item_seq.size(1), device=device).unsqueeze(0) < seq_len.unsqueeze(1)
        mask = mask.unsqueeze(2).float()
        hist_emb = (hist_emb * mask).sum(dim=1) / seq_len.unsqueeze(1).float().clamp(min=1)  # [B, E]
        
        # è¿æ¥ç”¨æˆ·åµŒå…¥å’Œå†å²ç‰©å“åµŒå…¥
        user_feature = torch.cat([user_emb, hist_emb], dim=1)  # [B, 2E]
        
        # ç”¨æˆ·å¡”DNN
        user_dnn_out = self.user_dnn(user_feature)  # [B, last_hidden]
        
        # ç›®æ ‡ç‰©å“Embedding
        item_emb = self.item_embedding(target_item)  # [B, E]
        
        # è®¡ç®—ç‚¹ç§¯
        if len(item_emb.shape) == 3:  # æ‰¹é‡è®¡ç®—å¤šä¸ªç‰©å“ [B, N, E]
            score = torch.bmm(user_dnn_out.unsqueeze(1), item_emb.transpose(1, 2)).squeeze(1)  # [B, N]
        else:  # å•ä¸ªç‰©å“ [B, E]
            score = torch.sum(user_dnn_out * item_emb, dim=1)  # [B]
        
        return score
    
    def get_user_embedding(self, user_id, hist_item_seq, seq_len):
        user_emb = self.user_embedding(user_id)
        hist_emb = self.hist_embedding(hist_item_seq)
        
        device = user_id.device
        mask = torch.arange(hist_item_seq.size(1), device=device).unsqueeze(0) < seq_len.unsqueeze(1)
        mask = mask.unsqueeze(2).float()
        hist_emb = (hist_emb * mask).sum(dim=1) / seq_len.unsqueeze(1).float().clamp(min=1)
        
        user_feature = torch.cat([user_emb, hist_emb], dim=1)
        user_dnn_out = self.user_dnn(user_feature)
        
        return user_dnn_out
    
    def get_item_embedding(self, item_id):
        return self.item_embedding(item_id)


# è·å–åŒå¡”å¬å›æ—¶çš„è®­ç»ƒéªŒè¯æ•°æ®
# negsampleæŒ‡çš„æ˜¯é€šè¿‡æ»‘çª—æ„å»ºæ ·æœ¬çš„æ—¶å€™ï¼Œè´Ÿæ ·æœ¬çš„æ•°é‡
def gen_data_set(data, negsample=0, max_hist_len=30):
    """
    ç”Ÿæˆè®­ç»ƒé›†å’Œæµ‹è¯•é›†
    
    Args:
        data: ç”¨æˆ·ç‚¹å‡»æ•°æ®
        negsample: æ¯ä¸ªæ­£æ ·æœ¬å¯¹åº”çš„è´Ÿæ ·æœ¬æ•°é‡
        max_hist_len: å†å²åºåˆ—çš„æœ€å¤§é•¿åº¦
        
    Returns:
        è®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„å…ƒç»„
    """
    data.sort_values("click_timestamp", inplace=True)
    item_ids = data['click_article_id'].unique()

    train_set = []
    test_set = []
    for reviewerID, hist in tqdm(data.groupby('user_id')):
        pos_list = hist['click_article_id'].tolist()

        if negsample > 0:
            candidate_set = list(set(item_ids) - set(pos_list))  # ç”¨æˆ·æ²¡çœ‹è¿‡çš„æ–‡ç« é‡Œé¢é€‰æ‹©è´Ÿæ ·æœ¬
            neg_list = np.random.choice(candidate_set, size=len(pos_list) * negsample, replace=True)  # å¯¹äºæ¯ä¸ªæ­£æ ·æœ¬ï¼Œé€‰æ‹©nä¸ªè´Ÿæ ·æœ¬

        # é•¿åº¦åªæœ‰ä¸€ä¸ªçš„æ—¶å€™ï¼Œéœ€è¦æŠŠè¿™æ¡æ•°æ®ä¹Ÿæ”¾åˆ°è®­ç»ƒé›†ä¸­ï¼Œä¸ç„¶çš„è¯æœ€ç»ˆå­¦åˆ°çš„embeddingå°±ä¼šæœ‰ç¼ºå¤±
        if len(pos_list) == 1:
            train_set.append((reviewerID, [pos_list[0]], pos_list[0], 1, 1))
            test_set.append((reviewerID, [pos_list[0]], pos_list[0], 1, 1))
            continue

        # æ»‘çª—æ„é€ æ­£è´Ÿæ ·æœ¬
        for i in range(1, len(pos_list)):
            hist = pos_list[:i]
            # é™åˆ¶å†å²åºåˆ—çš„æœ€å¤§é•¿åº¦
            hist = hist[-max_hist_len:] if len(hist) > max_hist_len else hist

            if i != len(pos_list) - 1:
                train_set.append((reviewerID, hist[::-1], pos_list[i], 1,
                                  len(hist[::-1])))  # æ­£æ ·æœ¬ [user_id, his_item, pos_item, label, len(his_item)]
                for negi in range(negsample):
                    train_set.append((reviewerID, hist[::-1], neg_list[i * negsample + negi], 0,
                                      len(hist[::-1])))  # è´Ÿæ ·æœ¬ [user_id, his_item, neg_item, label, len(his_item)]
            else:
                # å°†æœ€é•¿çš„é‚£ä¸€ä¸ªåºåˆ—é•¿åº¦ä½œä¸ºæµ‹è¯•æ•°æ®
                test_set.append((reviewerID, hist[::-1], pos_list[i], 1, len(hist[::-1])))

    random.shuffle(train_set)
    random.shuffle(test_set)

    return train_set, test_set


def train_youtube_dnn(train_dataloader, test_dataloader, model, device, epochs=5, 
                      learning_rate=0.001, weight_decay=1e-6):
    """
    è®­ç»ƒYouTubeDNNæ¨¡å‹
    """
    # å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
    criterion = nn.BCEWithLogitsLoss()
    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)

    # å°†æ¨¡å‹ç§»åŠ¨åˆ°è®¾å¤‡
    model.to(device)
    model.train()
    
    print(f"[train_youtube_dnn] æ¨¡å‹å·²åŠ è½½åˆ°è®¾å¤‡: {device}")
    print(f"[train_youtube_dnn] å¼€å§‹è®­ç»ƒ {epochs} è½®...")
    
    try:
        for epoch in range(epochs):
            train_loss = 0.0
            train_batches = 0
            
            # è®­ç»ƒå¾ªç¯
            for batch_idx, batch in enumerate(tqdm(train_dataloader, desc=f'Epoch {epoch+1}/{epochs}')):
                try:
                    user_id = batch['user_id'].to(device)
                    hist_item_seq = batch['hist_item_seq'].to(device)
                    target_item = batch['target_item'].to(device)
                    seq_len = batch['seq_len'].to(device)
                    label = batch['label'].float().to(device)
                    
                    # å‰å‘ä¼ æ’­
                    scores = model(user_id, hist_item_seq, target_item, seq_len)
                    loss = criterion(scores, label)
                    
                    # åå‘ä¼ æ’­å’Œä¼˜åŒ–
                    optimizer.zero_grad()
                    loss.backward()
                    optimizer.step()
                    
                    train_loss += loss.item()
                    train_batches += 1
                    
                    # æ¯100ä¸ªæ‰¹æ¬¡æ‰“å°ä¸€æ¬¡å½“å‰è®­ç»ƒçŠ¶æ€
                    if (batch_idx + 1) % 100 == 0:
                        print(f"  Batch {batch_idx+1}/{len(train_dataloader)}, Loss: {loss.item():.4f}")
                        
                except Exception as e:
                    print(f"[train_youtube_dnn] å¤„ç†æ‰¹æ¬¡ {batch_idx} æ—¶å‡ºé”™: {str(e)}")
                    print(f"æ‰¹æ¬¡ä¿¡æ¯: user_id shape={batch['user_id'].shape}, "
                          f"hist_item_seq shape={batch['hist_item_seq'].shape}, "
                          f"target_item shape={batch['target_item'].shape}, "
                          f"seq_len shape={batch['seq_len'].shape}, "
                          f"label shape={batch['label'].shape}")
                    continue
            
            # è¯„ä¼°æ¨¡å‹
            model.eval()
            val_loss = 0.0
            val_batches = 0
            
            with torch.no_grad():
                for batch in test_dataloader:
                    try:
                        user_id = batch['user_id'].to(device)
                        hist_item_seq = batch['hist_item_seq'].to(device)
                        target_item = batch['target_item'].to(device)
                        seq_len = batch['seq_len'].to(device)
                        label = batch['label'].float().to(device)
                        
                        scores = model(user_id, hist_item_seq, target_item, seq_len)
                        loss = criterion(scores, label)
                        
                        val_loss += loss.item()
                        val_batches += 1
                    except Exception as e:
                        print(f"[train_youtube_dnn] éªŒè¯æ—¶å‡ºé”™: {str(e)}")
                        continue
            
            model.train()
            
            # æ‰“å°æ¯ä¸ªepochçš„è®­ç»ƒå’ŒéªŒè¯æŸå¤±
            avg_train_loss = train_loss / max(1, train_batches)
            avg_val_loss = val_loss / max(1, val_batches)
            print(f'Epoch {epoch+1}/{epochs}, Train Loss: {avg_train_loss:.4f}, '
                  f'Val Loss: {avg_val_loss:.4f}')
    
    except Exception as e:
        print(f"[train_youtube_dnn] è®­ç»ƒè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
    
    print("[train_youtube_dnn] è®­ç»ƒå®Œæˆ!")
    return model


def youtubednn_u2i_dict(data, save_path="./cache/", topk=20, epochs=5, batch_size=256, embedding_dim=32):
    # å®šä¹‰æ‰€æœ‰ç¼“å­˜æ–‡ä»¶è·¯å¾„
    model_cache = os.path.join(save_path, 'youtube_model.pth')
    embeddings_cache = os.path.join(save_path, 'youtube_embeddings.pkl')
    cache_path = os.path.join(save_path, 'youtube_u2i_dict.pkl')
    
    print("[youtubednn_u2i_dict] ğŸš€ å¼€å§‹YouTubeDNNå¤„ç†...")
    
    # è·å–ç”¨æˆ·å’Œç‰©å“çš„ç¼–ç 
    user_encoder = LabelEncoder()
    item_encoder = LabelEncoder()
    
    # é‡æ–°ç¼–ç ç”¨æˆ·å’Œç‰©å“IDï¼Œç¡®ä¿IDä»0å¼€å§‹è¿ç»­
    data['user_id_encoded'] = user_encoder.fit_transform(data['user_id'])
    data['click_article_id_encoded'] = item_encoder.fit_transform(data['click_article_id'])
    
    # è·å–ç¼–ç åçš„ç”¨æˆ·å’Œç‰©å“æ•°é‡
    user_count = len(user_encoder.classes_)
    item_count = len(item_encoder.classes_)
    
    print(f"[youtubednn_u2i_dict] ç¼–ç å - ç”¨æˆ·æ•°é‡: {user_count}, ç‰©å“æ•°é‡: {item_count}")
    
    # åˆ›å»ºæ¨¡å‹å®ä¾‹ - ä½¿ç”¨ç¼–ç åçš„æ•°é‡
    model = YouTubeDNNModel(
        user_count, 
        item_count, 
        embedding_dim=embedding_dim,
        hidden_units=(128, 64, embedding_dim),
        dropout=0.3
    )
    
    # æ£€æŸ¥ç¼“å­˜
    if os.path.exists(model_cache):
        print(f"[youtubednn_u2i_dict] âœ… å‘ç°æ¨¡å‹ç¼“å­˜: {model_cache}")
        try:
            model.load_state_dict(torch.load(model_cache))
            print("[youtubednn_u2i_dict] âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
        except Exception as e:
            print(f"[youtubednn_u2i_dict] âš ï¸ åŠ è½½æ¨¡å‹å¤±è´¥: {str(e)}")
            print("[youtubednn_u2i_dict] å°†é‡æ–°è®­ç»ƒæ¨¡å‹")
            # ... è®­ç»ƒæ¨¡å‹çš„ä»£ç  ...
    
    # åˆå§‹åŒ–åµŒå…¥å˜é‡
    user_embeddings = {}
    item_embeddings = {}
    
    if os.path.exists(embeddings_cache):
        print(f"[youtubednn_u2i_dict] âœ… å‘ç°åµŒå…¥ç¼“å­˜: {embeddings_cache}")
        with open(embeddings_cache, 'rb') as f:
            cache_data = pickle.load(f)
            user_embeddings = cache_data['user_embeddings']
            item_embeddings = cache_data['item_embeddings']
    else:
        print("[youtubednn_u2i_dict] âš ï¸ æœªæ‰¾åˆ°åµŒå…¥ç¼“å­˜ï¼Œå°†é‡æ–°è®¡ç®—åµŒå…¥")
        model.eval()
        with torch.no_grad():
            # ä¸ºæ‰€æœ‰ç‰©å“è®¡ç®—åµŒå…¥
            encoded_items = torch.LongTensor(range(item_count))  # ä½¿ç”¨ç¼–ç åçš„ID
            item_embs = model.get_item_embedding(encoded_items).detach().cpu().numpy()
            
            # ä¿å­˜æ—¶ä½¿ç”¨åŸå§‹ID
            for idx, orig_item_id in enumerate(item_encoder.classes_):
                item_embeddings[orig_item_id] = item_embs[idx]
            
            # ä¸ºæ‰€æœ‰ç”¨æˆ·è®¡ç®—åµŒå…¥
            for user_id in tqdm(data['user_id'].unique(), desc="è®¡ç®—ç”¨æˆ·åµŒå…¥"):
                # è·å–ç”¨æˆ·çš„å†å²äº¤äº’
                user_hist = data[data['user_id'] == user_id]['click_article_id_encoded'].tolist()
                if not user_hist:
                    continue
                
                # å‡†å¤‡æ¨¡å‹è¾“å…¥
                encoded_user_id = user_encoder.transform([user_id])[0]
                hist_items = user_hist[-30:]  # æœ€å¤šä½¿ç”¨æœ€è¿‘30ä¸ªäº¤äº’
                hist_len = len(hist_items)
                hist_tensor = torch.LongTensor(hist_items + [0] * (30 - hist_len))
                hist_tensor = hist_tensor.unsqueeze(0)
                user_tensor = torch.LongTensor([encoded_user_id])
                seq_len = torch.LongTensor([hist_len])
                
                # è·å–ç”¨æˆ·åµŒå…¥
                try:
                    user_emb = model.get_user_embedding(user_tensor, hist_tensor, seq_len).numpy()
                    user_embeddings[user_id] = user_emb.squeeze() / np.linalg.norm(user_emb)
                except Exception as e:
                    print(f"[youtubednn_u2i_dict] âš ï¸ å¤„ç†ç”¨æˆ· {user_id} åµŒå…¥æ—¶å‡ºé”™: {str(e)}")
                    continue
        
        # ä¿å­˜åµŒå…¥
        cache_data = {
            'user_embeddings': user_embeddings,
            'item_embeddings': item_embeddings,
            'user_encoder': user_encoder,
            'item_encoder': item_encoder
        }
        with open(embeddings_cache, 'wb') as f:
            pickle.dump(cache_data, f)
    
    # ä½¿ç”¨Faissè¿›è¡Œå‘é‡æ£€ç´¢
    print("[youtubednn_u2i_dict] ä½¿ç”¨Faissè¿›è¡Œå‘é‡æ£€ç´¢...")
    user_ids = list(user_embeddings.keys())  # ä½¿ç”¨user_embeddingsè€Œä¸æ˜¯user_embs
    user_embs = np.array([user_embeddings[user_id] for user_id in user_ids], dtype=np.float32)
    
    item_ids = list(item_embeddings.keys())  # ä½¿ç”¨item_embeddingsè€Œä¸æ˜¯item_embs
    item_embs = np.array([item_embeddings[item_id] for item_id in item_ids], dtype=np.float32)
    
    # æ„å»ºç´¢å¼•
    index = faiss.IndexFlatIP(embedding_dim)
    index.add(item_embs)
    
    # æœç´¢æœ€ç›¸ä¼¼çš„ç‰©å“
    sim, idx = index.search(user_embs, topk)
    
    # ç”Ÿæˆå¬å›ç»“æœ
    user_recall_items_dict = {}
    for i, user_id in enumerate(user_ids):
        item_list = []
        for j, item_idx in enumerate(idx[i]):
            if item_idx < len(item_ids):  # é˜²æ­¢ç´¢å¼•è¶Šç•Œ
                item_id = item_ids[item_idx]
                score = sim[i][j]
                item_list.append((item_id, float(score)))
        user_recall_items_dict[user_id] = item_list
    
    # ä¿å­˜å¬å›ç»“æœ
    with open(cache_path, 'wb') as f:
        pickle.dump(user_recall_items_dict, f)
    
    print(f"[youtubednn_u2i_dict] âœ… å¬å›ç»“æœå·²ä¿å­˜è‡³: {cache_path}")
    
    # ä¿®æ”¹æ£€æŸ¥ä»£ç éƒ¨åˆ†
    print("[youtubednn_u2i_dict] æ£€æŸ¥åµŒå…¥è´¨é‡...")
    with torch.no_grad():
        # æŠ½æ ·æ£€æŸ¥ä¸€äº›ç”¨æˆ·åµŒå…¥å’Œç‰©å“åµŒå…¥çš„ä½™å¼¦ç›¸ä¼¼åº¦
        # ä»å­—å…¸ä¸­æŠ½æ ·ï¼Œè€Œä¸æ˜¯ä»numpyæ•°ç»„ä¸­æŠ½æ ·
        user_sample = list(user_embeddings.items())[:3]
        item_sample = list(item_embeddings.items())[:5]
        
        print("æ ·æœ¬ç”¨æˆ·åµŒå…¥:")
        for u_id, u_emb in user_sample:
            print(f"ç”¨æˆ·ID: {u_id}, åµŒå…¥èŒƒæ•°: {np.linalg.norm(u_emb)}")
            
            # æ£€æŸ¥ä¸æ ·æœ¬ç‰©å“çš„ç›¸ä¼¼åº¦
            for i_id, i_emb in item_sample:
                sim = np.dot(u_emb, i_emb) / (np.linalg.norm(u_emb) * np.linalg.norm(i_emb))
                print(f"  ä¸ç‰©å“ {i_id} çš„ç›¸ä¼¼åº¦: {sim:.4f}")
    
    return user_recall_items_dict 

def get_youtube_recall(train_df, val_df, save_path, use_cache=True, epochs=2, batch_size=256, embedding_dim=16):
    """
    ä½¿ç”¨PyTorchç‰ˆæœ¬çš„YouTubeDNNæ¨¡å‹ç”Ÿæˆç”¨æˆ·-ç‰©å“å¬å›è¡¨
    
    Args:
        train_df: è®­ç»ƒæ•°æ®
        val_df: éªŒè¯æ•°æ®
        save_path: ç»“æœä¿å­˜è·¯å¾„
        use_cache: æ˜¯å¦ä½¿ç”¨ç¼“å­˜
        epochs: è®­ç»ƒè½®æ•°
        batch_size: æ‰¹å¤§å°
        embedding_dim: åµŒå…¥ç»´åº¦
        
    Returns:
        ç”¨æˆ·-ç‰©å“å¬å›è¡¨ï¼Œæ ¼å¼ä¸º{ç”¨æˆ·ID: [(ç‰©å“ID, å¾—åˆ†), ...]}
    """
    # å®šä¹‰ç›¸å…³ç¼“å­˜è·¯å¾„
    cache_path = os.path.join(save_path, 'youtube_u2i_dict.pkl')
    model_path = os.path.join(save_path, 'youtube_dnn_model.pth')
    user_emb_path = os.path.join(save_path, 'user_youtube_emb.pkl') 
    item_emb_path = os.path.join(save_path, 'item_youtube_emb.pkl')
    
    # ç¡®ä¿ç›®å½•å­˜åœ¨
    os.makedirs(save_path, exist_ok=True)
    
    # æ£€æŸ¥å¬å›ç»“æœç¼“å­˜
    if use_cache and os.path.exists(cache_path):
        print(f"[get_youtube_recall] âœ… ä½¿ç”¨ç¼“å­˜ï¼š{cache_path}")
        with open(cache_path, 'rb') as f:
            return pickle.load(f)
    
    print("[get_youtube_recall] ğŸš€ ç”ŸæˆYouTubeDNNå¬å›ç»“æœ...")
    
    # ä»…ä½¿ç”¨ç”¨æˆ·å’Œç‰©å“IDï¼Œç®€åŒ–å¤„ç†
    df = pd.concat([train_df, val_df], ignore_index=True)
    user_count = df['user_id'].nunique() + 1  # +1 é¿å…ç´¢å¼•è¶Šç•Œ
    item_count = df['click_article_id'].nunique() + 1  # +1 é¿å…ç´¢å¼•è¶Šç•Œ
    
    # è·å–æ‰€æœ‰å”¯ä¸€ç”¨æˆ·å’Œç‰©å“ID
    unique_users = df['user_id'].unique()
    unique_items = df['click_article_id'].unique()
    
    # è·å–ç”¨æˆ·å†å²äº¤äº’
    user_hist_dict = {}
    for user_id, group in df.groupby('user_id'):
        user_hist_dict[user_id] = group.sort_values('click_timestamp')['click_article_id'].tolist()
    
    # åˆ›å»ºæ¨¡å‹
    model = YouTubeDNNModel(user_count, item_count, embedding_dim=embedding_dim)
    
    # æ£€æŸ¥æ¨¡å‹ç¼“å­˜
    if use_cache and os.path.exists(model_path):
        print(f"[get_youtube_recall] âœ… åŠ è½½é¢„è®­ç»ƒæ¨¡å‹ï¼š{model_path}")
        model.load_state_dict(torch.load(model_path))
    
    # æ£€æŸ¥åµŒå…¥ç¼“å­˜
    if use_cache and os.path.exists(user_emb_path) and os.path.exists(item_emb_path):
        print(f"[get_youtube_recall] âœ… åŠ è½½ç”¨æˆ·å’Œç‰©å“åµŒå…¥")
        with open(user_emb_path, 'rb') as f:
            user_embeddings = pickle.load(f)
        with open(item_emb_path, 'rb') as f:
            item_embeddings = pickle.load(f)
    else:
        # ç”Ÿæˆç”¨æˆ·å’Œç‰©å“çš„åµŒå…¥
        print("[get_youtube_recall] è®¡ç®—ç”¨æˆ·å’Œç‰©å“åµŒå…¥...")
        model.eval()
        
        # ä¸ºæ‰€æœ‰ç‰©å“ç”ŸæˆåµŒå…¥
        with torch.no_grad():
            all_item_ids = torch.LongTensor(unique_items)
            all_item_embs = model.get_item_embedding(all_item_ids).detach().numpy()
            normalized_item_embs = all_item_embs / np.linalg.norm(all_item_embs, axis=1, keepdims=True)
            
            # ä¿å­˜ç‰©å“åµŒå…¥å­—å…¸
            item_embeddings = {item_id: emb for item_id, emb in zip(unique_items, normalized_item_embs)}
            with open(item_emb_path, 'wb') as f:
                pickle.dump(item_embeddings, f)
        
        # è®¡ç®—ç”¨æˆ·åµŒå…¥
        user_embeddings = {}
        max_seq_len = 30
        
        with torch.no_grad():
            for user_id in tqdm(unique_users, desc="è®¡ç®—ç”¨æˆ·åµŒå…¥"):
                if user_id not in user_hist_dict or len(user_hist_dict[user_id]) == 0:
                    continue
                    
                # è·å–å†å²äº¤äº’ï¼Œç¡®ä¿å†…å®¹åœ¨item_countèŒƒå›´å†…
                hist_items = [i for i in user_hist_dict[user_id] if i < item_count]
                if not hist_items:
                    continue
                    
                # æœ€å¤šä½¿ç”¨æœ€è¿‘30ä¸ªäº¤äº’
                hist_items = hist_items[-max_seq_len:] if len(hist_items) > max_seq_len else hist_items
                hist_len = len(hist_items)
                
                # å°†å†å²äº¤äº’è½¬æ¢ä¸ºæ¨¡å‹è¾“å…¥ï¼Œç¡®ä¿paddingæ­£ç¡®
                hist_tensor = torch.LongTensor(hist_items + [0] * (max_seq_len - hist_len))
                hist_tensor = hist_tensor.unsqueeze(0)  # å¢åŠ æ‰¹æ¬¡ç»´åº¦
                user_tensor = torch.LongTensor([user_id])
                seq_len = torch.LongTensor([hist_len])
                
                # è·å–ç”¨æˆ·åµŒå…¥
                try:
                    user_emb = model.get_user_embedding(user_tensor, hist_tensor, seq_len).numpy()
                    user_embeddings[user_id] = user_emb.squeeze() / np.linalg.norm(user_emb)
                except Exception as e:
                    print(f"[get_youtube_recall] âš ï¸ å¤„ç†ç”¨æˆ· {user_id} åµŒå…¥æ—¶å‡ºé”™: {str(e)}")
                    continue
        
        # ä¿å­˜ç”¨æˆ·åµŒå…¥
        with open(user_emb_path, 'wb') as f:
            pickle.dump(user_embeddings, f)
    
    # å‡†å¤‡å‘é‡æ£€ç´¢
    print("[get_youtube_recall] ä½¿ç”¨Faissè¿›è¡Œå‘é‡æ£€ç´¢...")
    user_ids = list(user_embeddings.keys())
    user_embs = np.array([user_embeddings[user_id] for user_id in user_ids], dtype=np.float32)
    
    item_ids = list(item_embeddings.keys())
    item_embs = np.array([item_embeddings[item_id] for item_id in item_ids], dtype=np.float32)
    
    # æ„å»ºç´¢å¼•
    index = faiss.IndexFlatIP(embedding_dim)
    index.add(np.ascontiguousarray(item_embs))
    
    # ä¸ºéªŒè¯é›†ä¸­çš„ç”¨æˆ·ç”Ÿæˆå¬å›ç»“æœ
    user_recall_items_dict = {}
    topk = recall_num  # æ¯ä¸ªç”¨æˆ·å¬å›æŒ‡å®šæ•°é‡çš„æ–‡ç« 
    
    # æ‰§è¡Œå‘é‡æ£€ç´¢
    sim, idx = index.search(np.ascontiguousarray(user_embs), topk)
    
    # æ„å»ºç”¨æˆ·å¬å›ç»“æœ
    for i, user_id in enumerate(user_ids):
        item_list = []
        for j, item_idx in enumerate(idx[i]):
            if item_idx < len(item_ids):
                item_id = item_ids[item_idx]
                score = float(sim[i][j])
                item_list.append((item_id, score))
        user_recall_items_dict[user_id] = item_list
    
    # ä¿å­˜å¬å›ç»“æœ
    with open(cache_path, 'wb') as f:
        pickle.dump(user_recall_items_dict, f)
    
    print(f"[get_youtube_recall] âœ… å¬å›ç»“æœå·²ä¿å­˜è‡³ï¼š{cache_path}")
    return user_recall_items_dict 